{"cells":[{"metadata":{},"cell_type":"markdown","source":"# import"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport re\nimport datetime\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \n%matplotlib inline\n\n# Загружаем специальный удобный инструмент для разделения датасета:\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# всегда фиксируйте RANDOM_SEED, чтобы ваши эксперименты были воспроизводимы!\nRANDOM_SEED = 42","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зафиксируем версию пакетов, чтобы эксперименты были воспроизводимы:\n!pip freeze > requirements.txt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DATA"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"DATA_DIR = '/kaggle/input/sf-dst-restaurant-rating/'\ndf_train = pd.read_csv(DATA_DIR+'/main_task.csv')\ndf_test = pd.read_csv(DATA_DIR+'kaggle_task.csv')\nsample_submission = pd.read_csv(DATA_DIR+'/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ВАЖНО! дря корректной обработки признаков объединяем трейн и тест в один датасет\ndf_train['sample'] = 1 # помечаем где у нас трейн\ndf_test['sample'] = 0 # помечаем где у нас тест\ndf_test['Rating'] = 0 # в тесте у нас нет значения Rating, мы его должны предсказать, по этому пока просто заполняем нулями\n\ndf = df_test.append(df_train, sort=False).reset_index(drop=True) # объединяем","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подробнее по признакам:\n* City: Город \n* Cuisine Style: Кухня\n* Ranking: Ранг ресторана относительно других ресторанов в этом городе\n* Price Range: Цены в ресторане в 3 категориях\n* Number of Reviews: Количество отзывов\n* Reviews: 2 последних отзыва и даты этих отзывов\n* URL_TA: страница ресторана на 'www.tripadvisor.com' \n* ID_TA: ID ресторана в TripAdvisor\n* Rating: Рейтинг ресторана"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Reviews'][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in df.iloc[0:10]['URL_TA']:\n    print(item)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. # Cleaning and Prepaing Data"},{"metadata":{},"cell_type":"markdown","source":"##### Ranking"},{"metadata":{},"cell_type":"markdown","source":"Ranking является важным признаком для оценки популялярности. Однако имеет несколько недостатков:\n- Зависит от \"размера\" города, чем ниже ренкинг, тем больше зависимость. Ренкинг 100 в большом и небольшом городе - несравнимые показатели популярности.\n- Строгая иерария несколько натянута. Рестораны с ренкингом 3 и  23 в большом городе, фактически, одинаковы по популярности.\nПоэтому имеет смысл перевести показатели ренкинга в относительные единицы. Создадим новый признак, показывающий в какую группу по ренкигу в данном городе попадате ресторам. Создадим 10 групп: 1 - самые популярные, 10 - самые непопулярные."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предрасчитываем максимальный ренкинг по каждому городу\nranking_max = df.groupby(['City'])['Ranking'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция переводит абсолютный ренкинг ресторана в относителный\n# Количество групп задается параметром\ndef ranking_by_steps(row, q):\n    step = ranking_max[row['City']] / q\n    return math.ceil(row['Ranking'] / step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаем новый столбец, в который вносим данные по ренкингу в относительных единицах\n# 1 - 10% самых популярных, 10 - 10% самых непопулярных\ndf['Ranking Group'] = df.apply(lambda row: ranking_by_steps(row, 10), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Number of Reviews\nНе требует переработки"},{"metadata":{},"cell_type":"markdown","source":"##### Cuisine Style"},{"metadata":{},"cell_type":"markdown","source":"Из данных этого столбца можно извлечь информацию о разнобразии предлагаемой кухни. Мерой разнообразим можно считать количество стилей."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция преобразует строку с описанием стилей кухни в список этих стилей\ndef cousine_list(text):\n    if not text is np.nan:\n        cousine = []\n        regex = re.compile('\\'.+?\\'')\n        res = regex.findall(text)\n        for item in res:\n            cousine.append(item[1:-1])\n        return cousine\n    else:\n        return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция рассчитывает количество стилей кухни ресторана\ndef cousine_count(text):\n    if not text is np.nan:\n        return len(cousine_list(text))\n    else:\n        return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем новый столбец с количеством стилей кухни ресторана\ndf['Cuisine Style Quantity'] = df['Cuisine Style'].apply(cousine_count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создадим таблицу присутствия разных стилей в ресторанах\ncousine_count = {}\n\n# Создадим словарь с парой \"кухня - кол-во ресторанов, в которых данная кухня присутствует\"\nfor item in df['Cuisine Style']:\n    cousines = cousine_list(item)\n    if not cousines is np.nan:\n        for val in cousines:\n            if val in cousine_count:\n                cousine_count[val] += 1\n            else:\n                cousine_count[val] = 1\ncousine_count_df = pd.DataFrame(cousine_count,index=['quantity']).T.sort_values(by=['quantity'], ascending=False) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Отобразим, количество ресторанов, в которых присутствует данных стиль, чтобы оценить границы будущих групп\nax = cousine_count_df[0:20].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = cousine_count_df[16:60].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = cousine_count_df[60:100].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = cousine_count_df[80:].plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Можно выделить следующие границы, показывающие популярность кухни:\n\nсвыше 10 тыс. (общемировые),\nсвыше 1 тыс. (распространенные),\nсвыше 100 (редкие),\n100 и менее (экзотические).\nПредставляется, что популярность ресторана может зависить от двух факторов:\n\n- есть ли в его меню распространенная кухня (которая гарантированно подойдет большому числу посетителей)\n- есть ли в его меню экзотическая кухня (которая вызовет интерес у посетителей)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# В таблицу стилей кухи добавим информацию о распространенности кухни. Мерой выберем целом число логарифмированного количества ресторанов,\n# в котоорых присутсвует кухня. Две нижнии группы объединим в одну.\ndef wide_spread(cousine_count):\n    if np.log10(cousine_count) >= 2:\n        return int(np.log10(cousine_count))\n    else:\n        return 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Преобразуем индекс в столбец\n# cousine_count_df['cuisine'] = cousine_count_df.index\n# Добавлям столбец с данными по распространенности кухни\ncousine_count_df['wide_spread'] = cousine_count_df['quantity'].apply(wide_spread)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция для каждого ресторана определяет принадлежность его стилей к тому или иному классу распространнености\n# В зависимости от паратметра выдает максимальный или минимальный класс имеющихся у ресторана стилей\ndef cousine_spread(row, val='max'):\n    if not row['Cuisine Style'] is np.nan:  \n        cousines = cousine_list(row['Cuisine Style'])\n        spread = []\n        for item in cousines:\n            spread.append(cousine_count_df.loc[item,'wide_spread'])\n        spread.sort()\n        if val == 'max':\n            return spread[-1]\n        elif val == 'min':\n            return spread[0]\n        else:\n            return np.nan    \n    else:\n        return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем столбец класса с самой распространеной кухни\ndf['Cuisine Wide Spread'] = df.apply(lambda row: cousine_spread(row, 'max'), axis=1)\n\n# Добавляем столбец класса с самой экзотической кухней\ndf['Cuisine Exotic'] = df.apply(lambda row: cousine_spread(row, 'min'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Reviews"},{"metadata":{},"cell_type":"markdown","source":"Можем получить данные, связанные с датами отзывов. Например, количество дней между текущим дней и последним отзывом, и количество дней, между двумя отызывами. Также можем выделить рестораны, где отзыв только один."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Фунция извекает список с датами из текста\ndef review_dates(text):\n    dates = []\n    regex = re.compile('\\d\\d/\\d\\d\\/\\d\\d\\d\\d')\n    res = regex.findall(text)\n    for item in res:\n        dates.append(take_date(item))\n    if len(dates)!=0:\n        return dates\n    else:\n        np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция преобразует текст в даты\ndef take_date(text):\n    return datetime.datetime.strptime(text, \"%m/%d/%Y\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция рассчтиывает разницу между последним отзывом и текущей датой\ndef review_last_date(text):\n    if type(text) is str:\n        if review_dates(text)!=None:\n            return (datetime.datetime.today() - max(review_dates(text))).days\n        else:\n            return np.nan\n    else:\n        return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем столбец с разнице в дня между текущей датой и последним обзором\ndf['Review Last Date'] = df['Reviews'].apply(review_last_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция рассчитывает разницу в днях между двумя обзорами\ndef review_dif(text):\n    if type(text) is str:\n        dates = review_dates(text)\n        if dates!=None and len(dates)==2:\n            return abs((dates[0]-dates[1]).days)\n        else:\n            return np.nan  \n    else:\n        return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем столбец с разнице в днях между двумя обзорами\ndf['Review Date Dif'] = df['Reviews'].apply(review_dif)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Фунция рассчитывает количество отзывов на сайте\ndef reviews_quantity(row):\n    if not np.isnan(row['Review Last Date']) and not np.isnan(row['Review Date Dif']):\n        return 2\n    elif not np.isnan(row['Review Last Date']):\n        return 1\n    else:\n        return 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем столбец с количеством отзывов\ndf['Reviews Quantity'] = df.apply(lambda row: reviews_quantity(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Price Range"},{"metadata":{},"cell_type":"markdown","source":"Данные по уровню цен необходимо перевести в числовой форма."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция приводит даныне по уровню цен к числовому виду\ndef price_num(text):\n    if text=='$':\n        return 1.0\n    elif text=='$$ - $$$':\n        return 4.0\n    elif text=='$$$$':\n        return 7.0\n    else:\n        return np.nan","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем столбец с числовым предоставлением уровня цен\ndf['Price Range Num'] = df['Price Range'].apply(price_num)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Анализ пропусков"},{"metadata":{},"cell_type":"markdown","source":"##### Общая картина по пропускам"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Number of Reviews"},{"metadata":{},"cell_type":"markdown","source":"У малоизвестных ресторанов отзывов может не быть. Проверяем, фиксируется ли отсутствие отзывов значением 0 или нет."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['Number of Reviews'] == 0]['Number of Reviews'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Не фиксируется. Можно предположить, что NaN ставить в случае, когда у ресторана нет отзывов. Если это утверждение верно, тогда случаев NaN у популярных ресторанов должно быть незначительным, чем менее популярен ресторан, тем случаев NaN должно быть больше. Проверим это преположение.\nПроверим распределение NaN по ренкингу ресторанов. Для этого проанализуем распределение частоты NaN в группах ренкига по города. Создадим 4 группы (1 - входит в 25% самых популярных, 4 - входит в 25% самых не популярных)."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаем новый столбец, в который вносим данные по ренкингу в относительных единицах:\n# 1 - самые популярные, 4 - самые непопулярные\ndf['Ranking Group Test'] = df.apply(lambda row: ranking_by_steps(row, 4), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df['Number of Reviews'].isna()]['Ranking Group Test'].hist(bins=3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nНаше предположение оказалось верным: в самых популярных ресторанах NaN не зафиксирован, чем ниже популярность, тем выше доля Nan. То есть можно преположить, что вместо NaN должны быть нули.\nЗаменяем значения NaN на 0."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Number of Reviews'].fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Добавим еще один столбец, который нивелирует недостаток количества отзывав - размеры и популярность города.\nРассчитаем, какую долю ресторан занимает в своем городе по отзывам."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предрасчитываем данные\ncalculated = pd.DataFrame(df.groupby(['City'])['Number of Reviews'].sum())\n\n# Добавим показатель доли отзывов, приходящихся на ресторан в данном городе\ndef number_of_reviews_share(row):\n    return row['Number of Reviews'] / calculated.loc[row['City']]\n\ndf['Number of Reviews Share'] = df.apply(lambda row: number_of_reviews_share(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Cuisine Style Quantity,Cuisine Wide Spread,Cuisine Exotic"},{"metadata":{},"cell_type":"markdown","source":"Можно препроложить, что ресторан не размещает в своем профиле данные о принадлежности к той или иной кухне, если он предлагает наиболее распространенные стили. Сложно преположить, что предлагая экзотическую кухню, ресторан не укажет это."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверим, как распределены рестораны по свойствам Cuisine Wide Spread/ Cuisine Exotic\ndf.groupby(['Cuisine Wide Spread','Cuisine Exotic'])['Restaurant_id'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для ресторанов, у которых пропущен признак \"Cuisine Wide Spread\", установим его равным 4\ndf['Cuisine Wide Spread Nan'] = df['Cuisine Wide Spread'].isna().astype('int8')\ndf['Cuisine Wide Spread'].fillna(4, inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Для ресторанов, у которых пропущен признак \"Cuisine Exotic\", установим его равным мединанному значению\n# по группе 4 \"Cuisine Wide Spread\"\ndf['Cuisine Exotic Nan'] = df['Cuisine Exotic'].isna().astype('int8')\ndf['Cuisine Exotic'].fillna(df.loc[df['Cuisine Wide Spread']==4]['Cuisine Exotic'].median(), inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Количество стилей кухни установим равным медианному количеству в выборке \"Cuisine Wide Spread\" = 4\n# \"Cuisine Exotic\" = 3\ndf['Cuisine Style Quantity Nan'] = df['Cuisine Style Quantity'].isna().astype('int8')\ndf['Cuisine Style Quantity'].fillna(df.loc[(df['Cuisine Wide Spread']==4) & \n                                          (df['Cuisine Exotic']==3)]['Cuisine Style Quantity'].median(), inplace=True) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Review Last Date, Review Date Dif"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Устанавливаем признак, что в столбцах нет данных\ndf['Review Last Date Nan'] = df['Review Last Date'].isna().astype('int8')\ndf['Review Date Dif Nan'] = df['Review Date Dif'].isna().astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предрасчитываем данные для замены\ncalculated = pd.DataFrame(df.groupby(['City','Ranking Group'])['Review Last Date'].median())\nmax_last = df['Review Last Date'].max()\n\n# Функция замены Nan в столбце Review Last Date\n# Eсли количество отзывов равно нулю, то по ресторану нет отзывов\n# в этом случае проставляем максимальное значение по столбцу\n# Если количество не равно нулю, то отзывы есть, у нас не хватает данных. В этом случае проставляем\n# медианное значение по группе ренкинга и города\ndef last_date_change(row):\n    if row['Number of Reviews']==0:\n        return max_last\n    else:\n        return calculated.loc[(row['City'], row['Ranking Group'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Избавляемся от Nan\ndf.loc[df['Review Last Date'].isna(),'Review Last Date'] = df.apply(lambda row: last_date_change(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Предрасчитываем данные для замены\ncalculated = pd.DataFrame(df.groupby(['City','Ranking Group'])['Review Date Dif'].median())\nmax_dif = df['Review Date Dif'].max()\n\n# Функция замены Nan в столбце Review Date Dif\n# Eсли количество отзывов меньше 2, то по ресторану второго отзыва\n# в этом случае проствляем максимальное значение по столбцу\n# Если количество 2 и больше, то второй отзыв есть, у нас не хватает данных. В этом случае проставляем\n# медианное значение по группе ренкинга и города\ndef date_dif_change(row):\n    if not np.isnan(row['Review Date Dif']):\n        return row['Review Date Dif']\n    elif row['Number of Reviews']<2:\n        return max_dif\n    else:\n        return calculated.loc[(row['City'], row['Ranking Group'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Избавляемся от Nan\ndf['Review Date Dif'] = df.apply(lambda row: date_dif_change(row), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Price Range Num\nОтсутствующее указания ценового диапазона обычно свойственно более дешевым ресторанам"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Заменяет Nan\ndf['Price Range Num Nan'] = df['Price Range'].isna().astype('int8')\n# Отсутствующее указание ценового диапазона обычно свойственно более дешевым ресторанам\ndf['Price Range Num'].fillna(1, inplace=True)\ndf['Price Range Num'] = df['Price Range Num'].astype('int8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Города в отдельных столбцах"},{"metadata":{"trusted":true},"cell_type":"code","source":"# В первых 16-ти городов находится более 80% все ресторанов \ncities_with_freqs = list(df['City'].value_counts(normalize=True))\nsum(cities_with_freqs[0:16])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"main = df['City'].value_counts().index[0:16]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Функция оставляет первые 16-ть городов, остальные переименовывает в Others\ndef main_cities(text):\n    if text in main:\n        text = text\n    else:\n        text = 'Others'\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Добавляем столбцы-города\ndf['City New'] = df['City'].apply(main_cities)\ncity_dum = pd.get_dummies(df['City New'], drop_first=True)\ndf = df.join(city_dum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Удаляем лишние столбцы\ndf.drop(['City','Cuisine Style','Price Range','Reviews','URL_TA','ID_TA',\n        'City New', 'Ranking Group Test','Restaurant_id'],axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаем матрицу корреляции\nplt.rcParams['figure.figsize'] = (15,10)\nsns.heatmap(df.drop(['sample'], axis=1).corr(),)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Запускаем и проверяем что получилось"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc = df\ndf_preproc.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_preproc.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Теперь выделим тестовую часть\ntrain_data = df_preproc.query('sample == 1').drop(['sample'], axis=1)\ntest_data = df_preproc.query('sample == 0').drop(['sample'], axis=1)\n\ny = train_data.Rating.values            # наш таргет\nX = train_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Перед тем как отправлять наши данные на обучение, разделим данные на еще один тест и трейн, для валидации. \nЭто поможет нам проверить, как хорошо наша модель работает, до отправки submissiona на kaggle.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Воспользуемся специальной функцие train_test_split для разбивки тестовых данных\n# выделим 20% данных на валидацию (параметр test_size)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# проверяем\ntest_data.shape, train_data.shape, X.shape, X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model \nСам ML"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Импортируем необходимые библиотеки:\nfrom sklearn.ensemble import RandomForestRegressor # инструмент для создания и обучения модели\nfrom sklearn import metrics # инструменты для оценки точности модели","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Создаём модель (НАСТРОЙКИ НЕ ТРОГАЕМ)\nmodel = RandomForestRegressor(n_estimators=100, verbose=1, n_jobs=-1, random_state=RANDOM_SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Обучаем модель на тестовом наборе данных\nmodel.fit(X_train, y_train)\n\n# Используем обученную модель для предсказания рейтинга ресторанов в тестовой выборке.\n# Предсказанные значения записываем в переменную y_pred\ny_pred = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Сравниваем предсказанные значения (y_pred) с реальными (y_test), и смотрим насколько они в среднем отличаются\n# Метрика называется Mean Absolute Error (MAE) и показывает среднее отклонение предсказанных значений от фактических.\nprint('MAE:', metrics.mean_absolute_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# в RandomForestRegressor есть возможность вывести самые важные признаки для модели\nplt.rcParams['figure.figsize'] = (10,10)\nfeat_importances = pd.Series(model.feature_importances_, index=X.columns)\nfeat_importances.nlargest(15).plot(kind='barh')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission\nЕсли все устраевает - готовим Submission на кагл"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = test_data.drop(['Rating'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission['Rating'] = predict_submission\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}